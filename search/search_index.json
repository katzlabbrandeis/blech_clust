{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"blech_clust","text":"<p>Python and R based code for clustering and sorting electrophysiology data</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>blech_clust is a comprehensive Python and R based toolkit for clustering and sorting electrophysiology data recorded using the Intan RHD2132 chips. Originally written for cortical multi-electrode recordings in Don Katz's lab at Brandeis University, it's optimized for high-performance computing clusters but can be easily modified to work in any parallel environment.</p> <p>Visit the Katz lab website for more information.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Automated Spike Sorting: Complete pipeline from raw data to sorted units</li> <li>EMG Analysis: Multiple approaches including BSA/STFT and QDA-based gape detection</li> <li>Quality Assessment: Built-in tools for dataset quality grading and validation</li> <li>Parallel Processing: Optimized for HPC environments</li> <li>Comprehensive Documentation: Detailed API reference and tutorials</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Getting Started - Installation and setup instructions</li> <li>API Reference - Complete API documentation</li> <li>Tutorials - Step-by-step guides</li> <li>GitHub Repository</li> </ul>"},{"location":"#pipeline-overview","title":"Pipeline Overview","text":""},{"location":"#spike-sorting-pipeline","title":"Spike Sorting Pipeline","text":"<p>For the complete main spike-sorting pipeline (including the operations workflow diagram, detailed steps, and nomnoml schema), please refer to the README.</p>"},{"location":"#emg-analysis-pipelines","title":"EMG Analysis Pipelines","text":"<p>For details on EMG analysis workflows, see the README and Workflow Documentation.</p>"},{"location":"#installation","title":"Installation","text":"<p>The installation process is managed through a Makefile that handles all dependencies:</p> <pre><code># Clone the repository\ngit clone https://github.com/katzlabbrandeis/blech_clust.git\ncd blech_clust\n\n# Install everything\nmake all\n\n# Activate the environment\nconda activate blech_clust\n</code></pre> <p>For more detailed installation instructions, see the Getting Started guide.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! Please read our CONTRIBUTING.md file for guidelines.</p>"},{"location":"#contributing-to-documentation","title":"Contributing to Documentation","text":"<p>Help us improve the documentation:</p> <ul> <li>Report issues: Found an error or unclear explanation? Open an issue</li> <li>Suggest improvements: Have ideas for better organization or content? We'd love to hear them</li> <li>Submit changes: See docs/README.md for instructions on building and updating documentation</li> </ul> <p>The documentation is built with MkDocs and automatically deployed via GitHub Actions.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use this code in your research, please cite:</p> <pre><code>@software{blech_clust_katz,\n  author       = {Mahmood, Abuzar and\n                  Mukherjee, Narendra and\n                  Stone, Bradly and\n                  Raymond, Martin and\n                  Germaine, Hannah and\n                  Lin, Jian-You and\n                  Mazzio, Christina and\n                  Katz, Donald},\n  title        = {katzlabbrandeis/blech\\_clust: v1.1.0},\n  month        = apr,\n  year         = 2025,\n  publisher    = {Zenodo},\n  version      = {1.1.0},\n  doi          = {10.5281/zenodo.15175273},\n  url          = {https://doi.org/10.5281/zenodo.15175273}\n}\n</code></pre>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>This work used ACCESS-allocated resources at Brandeis University through allocation BIO230103 from the Advanced Cyberinfrastructure Coordination Ecosystem: Services &amp; Support (ACCESS) program, which is supported by U.S. National Science Foundation grants #2138259, #2138286, #2138307, #2137603, and #2138296.</p> <p>The project titled \"Computational Processing and Modeling of Neural Ensembles in Identifying the Nonlinear Dynamics of Taste Perception\" was led by PI Abuzar Mahmood. The computational allocation was active from 2023-06-26 to 2024-06-25.</p>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#workflow-walkthrough","title":"Workflow Walkthrough","text":"<p>This tutorial walks you through the complete spike sorting pipeline from raw data to analyzed units.</p>"},{"location":"tutorials/#step-1-experiment-information-setup","title":"Step 1: Experiment Information Setup","text":"<p>Open a terminal and run:</p> <pre><code>cd /path/to/blech_clust  # Make the blech_clust repository your working directory\nconda activate blech_clust  # Activate blech_clust environment\nDIR=/path/to/raw/data/files  # Save the path of the target Intan data to be sorted\npython blech_exp_info.py $DIR  # Generate metadata and electrode layout\n</code></pre>"},{"location":"tutorials/#configuring-car-groups","title":"Configuring CAR Groups","text":"<p>Once you've started running the script, it will ask you to \"fill in car groups\". Go to the Intan data folder, where you'll find a file named <code>[...]_electrode_layout.csv</code>.</p> <ol> <li>Open this file in a spreadsheet editor</li> <li>Fill in the <code>CAR_group</code> column</li> <li>Give all electrodes implanted in the same bundle the same identifier</li> <li>Use different identifiers for different bundles</li> <li>Example: All electrodes from a bundle in right GC are called <code>GC1</code>, and all electrodes from a bundle in left GC are called <code>GC2</code></li> <li>Return to the terminal and type <code>y</code> then press <code>enter</code></li> </ol>"},{"location":"tutorials/#selecting-digital-inputs","title":"Selecting Digital Inputs","text":"<p>The script will search your data folder for DIN files and print something like:</p> <pre><code>(0, 'board-DIN-09.dat'),\n(1, 'board-DIN-11.dat'),\n(2, 'board-DIN-12.dat'),\n(3, 'board-DIN-13.dat')\n</code></pre> <p>These are the files for the Intan digital inputs that correspond to stimulus presentations and/or laser activations.</p> <p>Prompt: <code>Taste dig_ins used (IN ORDER, anything separated) :: \"x\" to exit ::</code></p> <ul> <li>Select the DINs to include in later analysis steps</li> <li>Example: To include DINs 11 and 13 but not 09 or 12, type <code>1,3</code> and press <code>enter</code></li> <li>Note: If you have a DIN for laser activations, do not include it here; it will be requested later</li> </ul>"},{"location":"tutorials/#naming-tastes","title":"Naming Tastes","text":"<p>Prompt: <code>Tastes names used (IN ORDER, anything separated) :: \"x\" to exit ::</code></p> <ul> <li>Provide taste names for each selected DIN</li> <li>Example: If DIN-11 was DI H2O and DIN-13 was 300mM sucrose, enter <code>Water,Sucrose</code></li> <li>Leave off the molarity (provided in the next step)</li> </ul>"},{"location":"tutorials/#specifying-concentrations","title":"Specifying Concentrations","text":"<p>Prompt: <code>Corresponding concs used (in M, IN ORDER, COMMA separated) :: \"x\" to exit ::</code></p> <ul> <li>Provide numeric inputs for concentrations in Molarity</li> <li>Example: For DI H2O and 300mM sucrose, enter <code>0,0.3</code></li> </ul>"},{"location":"tutorials/#palatability-rankings","title":"Palatability Rankings","text":"<p>Prompt: <code>Enter palatability rankings used (anything separated), higher number = more palatable :: \"x\" to exit ::</code></p> <ul> <li>Provide numeric rankings (&gt; 0 and &lt;= number of stimuli)</li> <li>Can be non-integer and accept duplicates</li> <li>Valid examples: <code>4,3,2,1</code> or <code>0.4,0.3,0.2,0.1</code> or <code>3,2,2,1</code></li> <li>Invalid examples: <code>2,1,1,0</code> (contains 0) or <code>5,4,3,2</code> (exceeds number of stimuli)</li> <li>Example for water/sucrose: <code>1,2</code></li> </ul>"},{"location":"tutorials/#laser-configuration","title":"Laser Configuration","text":"<p>Prompt: <code>Laser dig_in index, &lt;BLANK&gt; for none::: \"x\" to exit ::</code></p> <ul> <li>If you have a laser DIN, enter its index (e.g., <code>0</code> for DIN-09)</li> <li>If no laser, just press <code>enter</code></li> </ul>"},{"location":"tutorials/#experiment-notes","title":"Experiment Notes","text":"<p>Prompt: <code>Please enter any notes about the experiment.</code></p> <ul> <li>Enter any pertinent comments or press <code>enter</code> to finish</li> </ul>"},{"location":"tutorials/#step-2-parameter-configuration","title":"Step 2: Parameter Configuration","text":"<p>Before running the clustering pipeline, set up parameter files:</p> <ol> <li>Copy <code>blech_clust/params/_templates/sorting_params_template.json</code> to <code>blech_clust/params/sorting_params_template.json</code></li> <li>Update the parameters as needed for your experiment</li> <li>Also copy and adapt:</li> <li><code>waveform_classifier_params.json</code></li> <li><code>emg_params.json</code></li> </ol>"},{"location":"tutorials/#step-3-run-the-pipeline","title":"Step 3: Run the Pipeline","text":""},{"location":"tutorials/#using-convenience-scripts","title":"Using Convenience Scripts","text":"<pre><code>bash blech_clust_pre.sh $DIR   # Perform steps up to spike extraction and UMAP\npython blech_post_process.py   # Add sorted units to HDF5 (CLI or .CSV as input)\nbash blech_clust_post.sh       # Perform steps up to PSTH generation\n</code></pre>"},{"location":"tutorials/#or-use-the-automated-script","title":"Or Use the Automated Script","text":"<pre><code>bash blech_autosort.sh &lt;data_directory&gt; [--force]\n</code></pre> <ul> <li><code>&lt;data_directory&gt;</code>: Path to the directory containing the raw data files</li> <li><code>--force</code>: Optional flag to force re-processing even if previous results exist</li> </ul> <p>The <code>blech_autosort.sh</code> script:</p> <ul> <li>Checks for required parameter files</li> <li>Verifies that specific settings are enabled</li> <li>Executes the pre-processing, clustering, and post-processing steps in sequence</li> </ul>"},{"location":"tutorials/#step-4-quality-assessment","title":"Step 4: Quality Assessment","text":"<p>After processing, assess the quality of your dataset:</p> <pre><code>python blech_units_characteristics.py  # Analyze unit characteristics\npython utils/blech_data_summary.py    # Generate comprehensive dataset summary\npython utils/grade_dataset.py         # Grade dataset quality based on metrics\n</code></pre>"},{"location":"tutorials/#emg-analysis-tutorial","title":"EMG Analysis Tutorial","text":""},{"location":"tutorials/#shared-setup","title":"Shared Setup","text":"<ol> <li>Complete spike sorting through <code>blech_make_arrays.py</code></li> <li>Filter EMG signals:    <pre><code>python emg_filter.py\n</code></pre></li> </ol>"},{"location":"tutorials/#bsastft-branch","title":"BSA/STFT Branch","text":"<p>For Bayesian Spectrum Analysis and Short-Time Fourier Transform:</p> <pre><code>python emg_freq_setup.py              # Configure parameters and generate parallel processing scripts\nbash blech_emg_jetstream_parallel.sh  # Run the generated parallel processing script\npython emg_freq_post_process.py       # Aggregate and process results\npython emg_freq_plot.py               # Generate visualizations\n</code></pre> <p>Note: The <code>emg_freq_setup.py</code> script generates the <code>blech_emg_jetstream_parallel.sh</code> script, which uses GNU parallel to process EMG signals in parallel.</p>"},{"location":"tutorials/#qda-branch","title":"QDA Branch","text":"<p>For Quadratic Discriminant Analysis (gape detection):</p> <pre><code>python emg_freq_setup.py                      # Setup parameters for gape detection\npython emg/gape_QDA_classifier/get_gapes_Li.py  # Detect gapes using QDA classifier\n</code></pre>"},{"location":"tutorials/#testing-your-installation","title":"Testing Your Installation","text":""},{"location":"tutorials/#local-testing-with-prefect","title":"Local Testing with Prefect","text":"<ol> <li> <p>Start the Prefect server in a separate terminal:    <pre><code>prefect server start\n</code></pre></p> </li> <li> <p>In another terminal, run the tests:    <pre><code>cd &lt;path_to_blech_clust&gt;\nmake prefect  # Install/update Prefect\n</code></pre></p> </li> <li> <p>Run specific test suites:    <pre><code># Run all tests\npython pipeline_testing/prefect_pipeline.py --all\n\n# Run only spike sorting tests\npython pipeline_testing/prefect_pipeline.py -s\n\n# Run only EMG analysis tests\npython pipeline_testing/prefect_pipeline.py -e\n\n# Run spike sorting followed by EMG analysis\npython pipeline_testing/prefect_pipeline.py --spike-emg\n</code></pre></p> </li> </ol> <p>Monitor test progress at http://localhost:4200</p>"},{"location":"tutorials/#advanced-topics","title":"Advanced Topics","text":""},{"location":"tutorials/#rnn-based-firing-rate-inference","title":"RNN-based Firing Rate Inference","text":"<p>Use the <code>infer_rnn_rates.py</code> utility to infer firing rates from spike trains:</p> <pre><code>python utils/infer_rnn_rates.py &lt;data_dir&gt; [options]\n</code></pre> <p>Options:</p> <ul> <li><code>--override_config</code>: Override config file and use provided arguments</li> <li><code>--train_steps TRAIN_STEPS</code>: Number of training steps (default: 15000)</li> <li><code>--hidden_size HIDDEN_SIZE</code>: Hidden size of RNN (default: 8)</li> <li><code>--bin_size BIN_SIZE</code>: Bin size for binning spikes (default: 25)</li> <li><code>--train_test_split TRAIN_TEST_SPLIT</code>: Fraction of data for training (default: 0.75)</li> <li><code>--no_pca</code>: Do not use PCA for preprocessing</li> <li><code>--retrain</code>: Force retraining of model</li> <li><code>--time_lims TIME_LIMS TIME_LIMS</code>: Time limits for inferred firing rates (default: [1500, 4500])</li> </ul>"},{"location":"tutorials/#additional-resources","title":"Additional Resources","text":"<ul> <li>Module Documentation: Detailed documentation for the ephys_data module</li> </ul>"},{"location":"workflow/","title":"Workflow Diagrams","text":"<p>This page provides additional visual representations and workflow details for the blech_clust pipeline.</p>"},{"location":"workflow/#main-spike-sorting-pipeline","title":"Main Spike-Sorting Pipeline","text":"<p>For the complete spike-sorting pipeline workflow (including the operations workflow diagram, detailed steps, and nomnoml schema), please refer to the README.</p>"},{"location":"workflow/#quality-assessment-workflow","title":"Quality Assessment Workflow","text":"<pre><code>blech_units_characteristics.py \u2192 blech_data_summary.py \u2192 grade_dataset.py\n</code></pre>"},{"location":"workflow/#additional-workflow-details","title":"Additional Workflow Details","text":""},{"location":"workflow/#spike-sorting-text-flow","title":"Spike Sorting Text Flow","text":"<pre><code>[blech_exp_info] -&gt; [blech_init]\n[blech_init] -&gt; [blech_common_average_reference]\n[blech_common_average_reference] -&gt; [bash blech_run_process.sh]\n[bash blech_run_process.sh] -&gt; [blech_post_process]\n[blech_post_process] -&gt; [blech_units_plot]\n[blech_units_plot] -&gt; [blech_make_arrays]\n[blech_make_arrays] -&gt; [bash blech_run_QA.sh]\n[bash blech_run_QA.sh] -&gt; [blech_units_characteristics]\n[blech_units_characteristics] -&gt; [blech_data_summary]\n[blech_data_summary] -&gt; [grade_dataset]\n</code></pre>"},{"location":"workflow/#emg-analysis-workflows","title":"EMG Analysis Workflows","text":"<p>Shared Steps:</p> <pre><code>[blech_init] -&gt; [blech_make_arrays]\n[blech_make_arrays] -&gt; [emg_filter]\n</code></pre> <p>BSA/STFT Branch:</p> <pre><code>[emg_filter] -&gt; [emg_freq_setup]\n[emg_freq_setup] -&gt; [bash blech_emg_jetstream_parallel.sh (generated)]\n[bash blech_emg_jetstream_parallel.sh] -&gt; [emg_freq_post_process]\n[emg_freq_post_process] -&gt; [emg_freq_plot]\n</code></pre> <p>Note: <code>emg_freq_setup.py</code> generates the <code>blech_emg_jetstream_parallel.sh</code> script for parallel processing.</p> <p>QDA Branch:</p> <pre><code>[emg_filter] -&gt; [emg_freq_setup]\n[emg_freq_setup] -&gt; [gape_QDA_classifier/get_gapes_Li]\n</code></pre>"},{"location":"workflow/#using-the-diagrams","title":"Using the Diagrams","text":""},{"location":"workflow/#viewing-the-workflow","title":"Viewing the Workflow","text":"<p>The operations workflow visual (available in the README) provides a high-level overview of the entire pipeline, showing how different components interact.</p>"},{"location":"workflow/#generating-custom-diagrams","title":"Generating Custom Diagrams","text":"<ol> <li>Visit nomnoml.com</li> <li>Copy the nomnoml schema code from the README</li> <li>Paste it into the editor</li> <li>Modify as needed for your specific use case</li> <li>Export as PNG or SVG</li> </ol>"},{"location":"workflow/#understanding-the-flow","title":"Understanding the Flow","text":"<ul> <li>Spike Sorting: The main pipeline processes raw Intan data through clustering and quality assessment</li> <li>EMG Analysis: Two parallel branches for different analysis approaches</li> <li>BSA/STFT: Frequency-based analysis using Bayesian methods</li> <li>QDA: Gape detection using quadratic discriminant analysis</li> </ul>"},{"location":"workflow/#see-also","title":"See Also","text":"<ul> <li>Main Spike-Sorting Pipeline (README)</li> <li>Core Pipeline Documentation</li> <li>Tutorials</li> <li>Getting Started</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing blech_clust, ensure you have:</p> <ul> <li>Conda/Miniconda: Required for environment management</li> <li>Git: For cloning repositories</li> <li>System packages: GNU parallel (optional, for parallel processing)</li> </ul>"},{"location":"getting-started/installation/#quick-start-recommended","title":"Quick Start (Recommended)","text":"<ol> <li> <p>Clone the repository: <pre><code>git clone https://github.com/katzlabbrandeis/blech_clust.git\ncd blech_clust\n</code></pre></p> </li> <li> <p>Install everything: <pre><code>make all\n</code></pre>    This installs the base environment, EMG analysis tools, neuRecommend classifier, and all optional dependencies.</p> </li> <li> <p>Activate the environment: <pre><code>conda activate blech_clust\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#custom-installation","title":"Custom Installation","text":"<p>For more control over what gets installed:</p> <pre><code># Core spike sorting functionality only\nmake core\n\n# Or install components individually:\nmake base      # Base environment and core dependencies (required)\nmake emg       # EMG analysis requirements (BSA/STFT, QDA)\nmake neurec    # neuRecommend waveform classifier\nmake prefect   # Prefect workflow management (for testing)\nmake dev       # Development dependencies\nmake optional  # Optional analysis tools\n</code></pre>"},{"location":"getting-started/installation/#parameter-setup","title":"Parameter Setup","text":"<p>After installation, set up parameter templates:</p> <pre><code># Copy parameter templates (if none exist)\nmake params\n\n# Edit the parameter files according to your experimental setup\n</code></pre>"},{"location":"getting-started/installation/#parameter-files","title":"Parameter Files","text":"<p>The following parameter files control pipeline behavior:</p> <ul> <li> <p>sorting_params.json - Spike sorting parameters:</p> <ul> <li><code>bandpass_lower_cutoff</code> / <code>bandpass_upper_cutoff</code>: Filter frequencies (default: 300-3000 Hz)</li> <li><code>waveform_threshold</code>: Spike detection threshold in standard deviations (default: 5)</li> <li><code>spike_snapshot_before</code> / <code>spike_snapshot_after</code>: Waveform extraction window in ms</li> <li><code>clustering_params</code>: GMM clustering settings</li> <li><code>qa_params</code>: Quality assurance thresholds</li> <li><code>psth_params</code>: PSTH calculation parameters</li> </ul> </li> <li> <p>emg_params.json - EMG analysis parameters:</p> <ul> <li><code>stft_params</code>: Short-time Fourier transform settings</li> <li><code>use_BSA</code>: Whether to use Bayesian Spectrum Analysis</li> </ul> </li> <li> <p>waveform_classifier_params.json - neuRecommend classifier settings</p> </li> </ul>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>Clean installation: If you encounter issues, remove the environment and start fresh:   <pre><code>make clean\nmake all\n</code></pre></p> </li> <li> <p>Partial installation: If a component fails, you can retry individual components:   <pre><code>make base    # Retry base installation\nmake emg     # Retry EMG components\n</code></pre></p> </li> <li> <p>Environment activation: Always activate the environment before running scripts:   <pre><code>conda activate blech_clust\n</code></pre></p> </li> </ul>"},{"location":"getting-started/installation/#test-dataset","title":"Test Dataset","text":"<p>A test dataset is available to verify your installation:</p> <p>Test Dataset on Google Drive</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the API Reference to understand available functions</li> <li>Read the Tutorials for step-by-step guides</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":""},{"location":"getting-started/quickstart/#first-steps","title":"First Steps","text":"<p>Once installed, you can start processing your data:</p> <ol> <li>Prepare your data: Ensure you have Intan RHD2132 recordings</li> <li>Set up experiment info: Run <code>python blech_exp_info.py</code> to annotate channels</li> <li>Configure parameters: Edit the parameter files in the <code>params/</code> directory</li> <li>Run the pipeline: Use the convenience scripts or run individual modules</li> </ol>"},{"location":"getting-started/quickstart/#basic-workflow","title":"Basic Workflow","text":""},{"location":"getting-started/quickstart/#1-experiment-setup","title":"1. Experiment Setup","text":"<pre><code># Activate the environment\nconda activate blech_clust\n\n# Navigate to your data directory\ncd /path/to/your/data\n\n# Run experiment info setup\npython /path/to/blech_clust/blech_exp_info.py\n</code></pre> <p>This will guide you through annotating your channels and setting up experimental parameters.</p>"},{"location":"getting-started/quickstart/#2-data-initialization","title":"2. Data Initialization","text":"<pre><code># Initialize directory structure and prepare data\npython /path/to/blech_clust/blech_init.py\n</code></pre> <p>This creates the necessary directory structure and organizes data files.</p>"},{"location":"getting-started/quickstart/#3-common-average-referencing","title":"3. Common Average Referencing","text":"<pre><code># Perform common average referencing\npython /path/to/blech_clust/blech_common_avg_reference.py\n</code></pre>"},{"location":"getting-started/quickstart/#4-spike-extraction-and-clustering","title":"4. Spike Extraction and Clustering","text":"<pre><code># Run parallel processing\nbash /path/to/blech_clust/blech_run_process.sh\n</code></pre> <p>This runs spike extraction and clustering in parallel across electrodes.</p>"},{"location":"getting-started/quickstart/#5-post-processing","title":"5. Post-Processing","text":"<pre><code># Add selected units to HDF5\npython /path/to/blech_clust/blech_post_process.py\n\n# Plot waveforms\npython /path/to/blech_clust/blech_units_plot.py\n\n# Generate spike arrays\npython /path/to/blech_clust/blech_make_arrays.py\n</code></pre>"},{"location":"getting-started/quickstart/#6-quality-assessment","title":"6. Quality Assessment","text":"<pre><code># Run QA checks\nbash /path/to/blech_clust/blech_run_QA.sh\n\n# Analyze unit characteristics\npython /path/to/blech_clust/blech_units_characteristics.py\n\n# Generate data summary\npython /path/to/blech_clust/blech_data_summary.py\n\n# Grade dataset quality\npython /path/to/blech_clust/grade_dataset.py\n</code></pre>"},{"location":"getting-started/quickstart/#emg-analysis","title":"EMG Analysis","text":"<p>If you have EMG data, you can run the EMG analysis pipeline:</p> <pre><code># Filter EMG signals\npython /path/to/blech_clust/emg/emg_filter.py\n\n# Setup frequency analysis parameters\npython /path/to/blech_clust/emg/emg_freq_setup.py\n\n# Choose your analysis approach:\n\n# Option 1: BSA/STFT frequency analysis\npython /path/to/blech_clust/emg/emg_freq_post_process.py\npython /path/to/blech_clust/emg/emg_freq_plot.py\n\n# Option 2: QDA-based gape detection\npython /path/to/blech_clust/emg/gape_QDA_classifier/get_gapes_Li.py\n</code></pre>"},{"location":"getting-started/quickstart/#parameter-configuration","title":"Parameter Configuration","text":"<p>Key parameter files to configure:</p> <ul> <li>clustering_params.json: Clustering algorithm parameters</li> <li>spike_detection_params.json: Spike detection thresholds</li> <li>emg_params.json: EMG analysis parameters (if using EMG)</li> </ul>"},{"location":"getting-started/quickstart/#tips","title":"Tips","text":"<ul> <li>Always activate the conda environment before running scripts</li> <li>Check log files in the output directories for debugging</li> <li>Use the test dataset to verify your installation</li> <li>Refer to the API Reference for detailed function documentation</li> </ul>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the Tutorials for detailed walkthroughs</li> <li>Check the API Reference for function details</li> </ul>"},{"location":"reference/","title":"API Reference","text":"<p>This section contains the API documentation for blech_clust modules.</p>"},{"location":"reference/#overview","title":"Overview","text":"<p>The blech_clust codebase is organized into several key modules:</p> <ul> <li>Core Pipeline - Main spike sorting pipeline modules</li> <li>Utilities - Helper functions and utility classes</li> <li>EMG Analysis - EMG signal processing and analysis</li> </ul>"},{"location":"reference/#module-organization","title":"Module Organization","text":""},{"location":"reference/#core-pipeline-modules","title":"Core Pipeline Modules","text":"<p>Located in the repository root, these modules form the main spike sorting pipeline:</p> <ul> <li><code>blech_exp_info.py</code> - Experiment setup and metadata</li> <li><code>blech_init.py</code> - Directory initialization and data preparation</li> <li><code>blech_common_avg_reference.py</code> - Common average referencing</li> <li><code>blech_process.py</code> - Spike extraction and clustering</li> <li><code>blech_post_process.py</code> - Post-processing and unit selection</li> <li><code>blech_units_plot.py</code> - Waveform visualization</li> <li><code>blech_make_arrays.py</code> - Spike train array generation</li> </ul>"},{"location":"reference/#utility-modules","title":"Utility Modules","text":"<p>Located in <code>utils/</code>, these provide supporting functionality:</p> <ul> <li><code>blech_utils.py</code> - Core utility functions</li> <li><code>clustering/</code> - Clustering algorithms</li> <li><code>ephys_data/</code> - Electrophysiology data handling</li> <li><code>qa_utils/</code> - Quality assurance tools</li> </ul>"},{"location":"reference/#emg-modules","title":"EMG Modules","text":"<p>Located in <code>emg/</code>, these handle EMG signal analysis:</p> <ul> <li><code>emg_filter.py</code> - EMG signal filtering</li> <li><code>emg_freq_setup.py</code> - Frequency analysis setup</li> <li><code>get_gapes_Li.py</code> - Gape detection using QDA</li> </ul>"},{"location":"reference/#using-the-api","title":"Using the API","text":""},{"location":"reference/#importing-modules","title":"Importing Modules","text":"<pre><code># Import utility functions\nfrom utils.blech_utils import Tee, path_handler, imp_metadata\n\n# Import ephys data tools\nfrom utils.ephys_data import ephys_data\n\n# Import clustering utilities\nfrom utils.clustering import clustering\n</code></pre>"},{"location":"reference/#example-usage","title":"Example Usage","text":"<pre><code># Load experimental data\nfrom utils.ephys_data import ephys_data\n\n# Create data handler\ndata = ephys_data('/path/to/data')\n\n# Access spike trains\nspike_trains = data.spikes\n\n# Get unit information\nunits = data.units\n</code></pre>"},{"location":"reference/#documentation-format","title":"Documentation Format","text":"<p>Each module page includes:</p> <ul> <li>Overview - Module purpose and functionality</li> <li>Key Functions/Classes - Main components with descriptions</li> <li>Usage Examples - Code examples demonstrating usage</li> <li>Parameters - Detailed parameter descriptions</li> <li>Returns - Return value descriptions</li> </ul>"},{"location":"reference/#contributing","title":"Contributing","text":"<p>To improve the API documentation:</p> <ol> <li>Update docstrings in the source code following NumPy format</li> <li>Submit a pull request with your changes</li> <li>Documentation will be automatically rebuilt</li> </ol> <p>See CONTRIBUTING.md for guidelines.</p>"},{"location":"reference/core-pipeline/","title":"Core Pipeline","text":"<p>The core pipeline modules handle the main spike sorting workflow from raw data to sorted units.</p>"},{"location":"reference/core-pipeline/#pipeline-modules","title":"Pipeline Modules","text":""},{"location":"reference/core-pipeline/#blech_exp_infopy","title":"blech_exp_info.py","text":"<p>Pre-clustering step to annotate channels and save experimental parameters.</p> <p>Key Functions:</p> <ul> <li>Electrode layout configuration</li> <li>Digital input selection</li> <li>Taste/stimulus naming</li> <li>Palatability ranking</li> <li>Laser configuration</li> </ul> <p>Usage:</p> <pre><code>python blech_exp_info.py /path/to/data\n</code></pre>"},{"location":"reference/core-pipeline/#blech_initpy","title":"blech_init.py","text":"<p>Initialize directories and prepare data for clustering.</p> <p>Key Functions:</p> <ul> <li>Directory structure creation</li> <li>Data file organization</li> <li>Initial parameter setup</li> </ul> <p>Usage:</p> <pre><code>python blech_init.py\n</code></pre>"},{"location":"reference/core-pipeline/#blech_common_avg_referencepy","title":"blech_common_avg_reference.py","text":"<p>Perform common average referencing on electrode data.</p> <p>Key Functions:</p> <ul> <li>CAR group processing</li> <li>Signal referencing</li> <li>Artifact reduction</li> </ul> <p>Usage:</p> <pre><code>python blech_common_avg_reference.py\n</code></pre>"},{"location":"reference/core-pipeline/#blech_processpy","title":"blech_process.py","text":"<p>Core spike extraction and clustering module.</p> <p>Key Functions:</p> <ul> <li>Spike detection</li> <li>Feature extraction</li> <li>Clustering algorithms</li> <li>UMAP dimensionality reduction</li> </ul> <p>Usage:</p> <pre><code># Usually called via blech_run_process.sh for parallel execution\npython blech_process.py &lt;electrode_number&gt;\n</code></pre>"},{"location":"reference/core-pipeline/#blech_post_processpy","title":"blech_post_process.py","text":"<p>Add selected units to HDF5 file after manual curation.</p> <p>Key Functions:</p> <ul> <li>Unit selection</li> <li>HDF5 file updates</li> <li>Metadata management</li> </ul> <p>Usage:</p> <pre><code>python blech_post_process.py\n</code></pre>"},{"location":"reference/core-pipeline/#blech_units_plotpy","title":"blech_units_plot.py","text":"<p>Plot waveforms of selected spikes for visualization.</p> <p>Key Functions:</p> <ul> <li>Waveform plotting</li> <li>Unit visualization</li> <li>Quality metrics display</li> </ul> <p>Usage:</p> <pre><code>python blech_units_plot.py\n</code></pre>"},{"location":"reference/core-pipeline/#blech_make_arrayspy","title":"blech_make_arrays.py","text":"<p>Generate spike-train arrays for analysis.</p> <p>Key Functions:</p> <ul> <li>Spike train generation</li> <li>Trial alignment</li> <li>Array formatting</li> </ul> <p>Usage:</p> <pre><code>python blech_make_arrays.py\n</code></pre>"},{"location":"reference/core-pipeline/#pipeline-flow","title":"Pipeline Flow","text":"<pre><code>Raw Data\n    \u2193\nblech_exp_info.py (Setup)\n    \u2193\nblech_init.py (Initialization)\n    \u2193\nblech_common_avg_reference.py (Referencing)\n    \u2193\nblech_run_process.sh (Parallel Processing)\n    \u2193\nblech_post_process.py (Unit Selection)\n    \u2193\nblech_units_plot.py (Visualization)\n    \u2193\nblech_make_arrays.py (Array Generation)\n    \u2193\nSorted Units\n</code></pre>"},{"location":"reference/core-pipeline/#configuration-files","title":"Configuration Files","text":"<p>The pipeline uses several JSON configuration files:</p> <ul> <li><code>sorting_params.json</code> - Clustering parameters</li> <li><code>spike_detection_params.json</code> - Detection thresholds</li> <li><code>waveform_classifier_params.json</code> - Classifier settings</li> </ul>"},{"location":"reference/core-pipeline/#see-also","title":"See Also","text":"<ul> <li>Getting Started</li> <li>Tutorials</li> <li>Utilities</li> </ul>"},{"location":"reference/emg-analysis/","title":"EMG Analysis","text":"<p>Tools for analyzing electromyography (EMG) signals, including frequency analysis and gape detection.</p>"},{"location":"reference/emg-analysis/#overview","title":"Overview","text":"<p>The EMG analysis pipeline uses BSA/STFT (Bayesian Spectrum Analysis and Short-Time Fourier Transform) for frequency analysis.</p>"},{"location":"reference/emg-analysis/#shared-setup","title":"Shared Setup","text":""},{"location":"reference/emg-analysis/#emg_filterpy","title":"emg_filter.py","text":"<p>Filter EMG signals before analysis.</p> <p>Usage:</p> <pre><code>python emg/emg_filter.py\n</code></pre> <p>Filtering Steps:</p> <ol> <li>Differencing EMG channels within CAR groups (if multiple channels)</li> <li>Highpass filtering at 300 Hz (2nd order Butterworth)</li> <li>Rectification (absolute value)</li> <li>Lowpass filtering at 15 Hz for envelope extraction</li> </ol> <p>Output:</p> <ul> <li>Filtered EMG signals saved to HDF5 file</li> <li>Filter parameters logged</li> </ul>"},{"location":"reference/emg-analysis/#bsastft-branch","title":"BSA/STFT Branch","text":"<p>Frequency-based analysis of EMG signals.</p>"},{"location":"reference/emg-analysis/#emg_freq_setuppy","title":"emg_freq_setup.py","text":"<p>Configure parameters for frequency analysis.</p> <p>Usage:</p> <pre><code>python emg/emg_freq_setup.py\n</code></pre> <p>Parameters:</p> <ul> <li>Frequency bands of interest</li> <li>Window sizes</li> <li>Overlap parameters</li> <li>Output directories</li> </ul>"},{"location":"reference/emg-analysis/#parallel-processing","title":"Parallel Processing","text":"<p>Run frequency analysis in parallel:</p> <pre><code>bash blech_emg_jetstream_parallel.sh\n</code></pre> <p>Note: This script is automatically generated by <code>emg_freq_setup.py</code> and uses GNU parallel for distributed processing.</p> <p>The script:</p> <ol> <li>Divides trials across processors</li> <li>Runs BSA/STFT on each subset</li> <li>Saves intermediate results</li> </ol>"},{"location":"reference/emg-analysis/#emg_freq_post_processpy","title":"emg_freq_post_process.py","text":"<p>Aggregate and process frequency analysis results.</p> <p>Usage:</p> <pre><code>python emg/emg_freq_post_process.py\n</code></pre> <p>Processing Steps:</p> <ol> <li>Combine results from parallel jobs</li> <li>Normalize power spectra</li> <li>Calculate summary statistics</li> <li>Identify significant frequency changes</li> </ol>"},{"location":"reference/emg-analysis/#emg_freq_plotpy","title":"emg_freq_plot.py","text":"<p>Generate visualizations of frequency analysis.</p> <p>Usage:</p> <pre><code>python emg/emg_freq_plot.py\n</code></pre> <p>Plots Generated:</p> <ul> <li>Spectrograms</li> <li>Power spectrum time courses</li> <li>Frequency band comparisons</li> <li>Trial-averaged responses</li> </ul>"},{"location":"reference/emg-analysis/#emg-data-structure","title":"EMG Data Structure","text":""},{"location":"reference/emg-analysis/#hdf5-organization","title":"HDF5 Organization","text":"<pre><code>data.h5\n\u251c\u2500\u2500 emg_data/\n\u2502   \u251c\u2500\u2500 dig_in_&lt;N&gt;/\n\u2502   \u2502   \u251c\u2500\u2500 emg_array           # Raw EMG data\n\u2502   \u2502   \u2514\u2500\u2500 processed_emg/\n\u2502   \u2502       \u251c\u2500\u2500 &lt;car&gt;_emg_filt  # Highpass filtered signal\n\u2502   \u2502       \u2514\u2500\u2500 &lt;car&gt;_emg_env   # Envelope (lowpass filtered)\n\u2502   \u251c\u2500\u2500 ind_electrode_map       # Electrode mapping\n\u2502   \u2514\u2500\u2500 emg_sig_trials          # Significant trial indicators\n\u251c\u2500\u2500 emg_BSA_results/            # BSA/STFT frequency analysis\n\u2502   \u251c\u2500\u2500 omega                   # Frequency values\n\u2502   \u251c\u2500\u2500 &lt;car&gt;/\n\u2502   \u2502   \u2514\u2500\u2500 taste&lt;N&gt;_p          # Power spectrum per taste\n\u2502   \u251c\u2500\u2500 gapes                   # Detected gape events\n\u2502   \u251c\u2500\u2500 licking                 # Detected licking events\n\u2502   \u2514\u2500\u2500 emg_BSA_results_final   # Combined results\n</code></pre>"},{"location":"reference/emg-analysis/#configuration","title":"Configuration","text":""},{"location":"reference/emg-analysis/#emg_paramsjson","title":"emg_params.json","text":"<p>EMG analysis parameters:</p> <pre><code>{\n    \"emg_env\": \"/path/to/conda/envs/emg_env\",\n    \"stft_params\": {\n        \"max_freq\": 20,\n        \"time_range_tuple\": [0, 7],\n        \"Fs\": 1000,\n        \"signal_window\": 400,\n        \"window_overlap\": 399\n    },\n    \"use_BSA\": true\n}\n</code></pre> <ul> <li><code>emg_env</code>: Path to conda environment for EMG processing</li> <li><code>stft_params</code>: Short-time Fourier transform parameters<ul> <li><code>max_freq</code>: Maximum frequency to analyze (Hz)</li> <li><code>time_range_tuple</code>: Time window for analysis (seconds)</li> <li><code>Fs</code>: Sampling frequency (Hz)</li> <li><code>signal_window</code>: Window size for STFT (samples)</li> <li><code>window_overlap</code>: Overlap between windows (samples)</li> </ul> </li> <li><code>use_BSA</code>: Whether to use Bayesian Spectrum Analysis (true) or STFT (false)</li> </ul>"},{"location":"reference/emg-analysis/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/emg-analysis/#complete-bsastft-workflow","title":"Complete BSA/STFT Workflow","text":"<pre><code># Filter EMG signals\npython emg/emg_filter.py\n\n# Setup frequency analysis\npython emg/emg_freq_setup.py\n\n# Run parallel analysis\nbash blech_emg_jetstream_parallel.sh\n\n# Post-process results\npython emg/emg_freq_post_process.py\n\n# Generate plots\npython emg/emg_freq_plot.py\n</code></pre>"},{"location":"reference/emg-analysis/#programmatic-access","title":"Programmatic Access","text":"<pre><code>import tables\nimport numpy as np\n\n# Load filtered EMG data\nwith tables.open_file('data.h5', 'r') as hf5:\n    emg_filtered = hf5.root.emg.filtered[:]\n\n# Load gape events\nwith tables.open_file('data.h5', 'r') as hf5:\n    gape_times = hf5.root.emg.gapes.onset_times[:]\n    gape_durations = hf5.root.emg.gapes.durations[:]\n\n# Analyze gape timing\nprint(f\"Detected {len(gape_times)} gapes\")\nprint(f\"Mean duration: {np.mean(gape_durations):.2f} ms\")\n</code></pre>"},{"location":"reference/emg-analysis/#analysis-tips","title":"Analysis Tips","text":""},{"location":"reference/emg-analysis/#frequency-analysis","title":"Frequency Analysis","text":"<ul> <li>Use appropriate frequency bands for your species/preparation</li> <li>Adjust window size based on temporal resolution needs</li> <li>Consider trial-to-trial variability</li> </ul>"},{"location":"reference/emg-analysis/#quality-control","title":"Quality Control","text":"<ul> <li>Inspect filtered signals visually</li> <li>Check for artifacts</li> <li>Validate detected events manually for subset of trials</li> </ul>"},{"location":"reference/emg-analysis/#references","title":"References","text":"<ul> <li>Mukherjee, N., Wachutka, J., &amp; Katz, D. B. (2019). Impact of precisely-timed inhibition of gustatory cortex on taste behavior depends on single-trial ensemble dynamics. eLife, 8, e45968.</li> <li>Li JX, Maier JX, Reid EE, Katz DB. Sensory Cortical Activity Is Related to the Selection of a Rhythmic Motor Action Pattern. J Neurosci. 2016 May 18;36(20):5596-607. doi: 10.1523/JNEUROSCI.3949-15.2016. PMID: 27194338; PMCID: PMC4871991.</li> </ul>"},{"location":"reference/emg-analysis/#see-also","title":"See Also","text":"<ul> <li>Core Pipeline</li> <li>Utilities</li> <li>Tutorials</li> </ul>"},{"location":"reference/utilities/","title":"Utilities","text":"<p>Utility modules provide supporting functionality for the spike sorting pipeline.</p>"},{"location":"reference/utilities/#blech_utils","title":"blech_utils","text":"<p>Core utility functions used throughout the codebase.</p>"},{"location":"reference/utilities/#key-classes-and-functions","title":"Key Classes and Functions","text":""},{"location":"reference/utilities/#tee","title":"Tee","text":"<p>Redirect stdout to both console and file for logging.</p> <pre><code>from utils.blech_utils import Tee\nimport sys\n\n# Redirect output to file and console\nsys.stdout = Tee('/path/to/data/dir', name='logfile.txt')\nprint(\"This goes to both console and file\")\n</code></pre>"},{"location":"reference/utilities/#path_handler","title":"path_handler","text":"<p>Handle file paths and directory operations.</p> <pre><code>from utils.blech_utils import path_handler\n\n# Instantiate path handler\nph = path_handler()\n\n# Access blech_clust directory\nblech_dir = ph.blech_clust_dir\n\n# Access home directory\nhome = ph.home_dir\n</code></pre>"},{"location":"reference/utilities/#imp_metadata","title":"imp_metadata","text":"<p>Import and manage experimental metadata.</p> <pre><code>from utils.blech_utils import imp_metadata\nimport sys\n\n# Load metadata (requires sys.argv or list with directory path)\nmetadata = imp_metadata([sys.argv, '/path/to/data'])\n\n# Access metadata attributes\nhdf5_name = metadata.hdf5_name\ninfo_dict = metadata.info_dict\nlayout_df = metadata.layout\n</code></pre>"},{"location":"reference/utilities/#clustering-utilities","title":"Clustering Utilities","text":"<p>Located in <code>utils/clustering/</code>, these modules provide clustering algorithms and tools.</p>"},{"location":"reference/utilities/#key-functions","title":"Key Functions","text":"<ul> <li>Spike clustering algorithms</li> <li>Feature extraction</li> <li>Cluster validation</li> <li>Merge/split operations</li> </ul>"},{"location":"reference/utilities/#data-management","title":"Data Management","text":""},{"location":"reference/utilities/#ephys_data-module","title":"ephys_data Module","text":"<p>Comprehensive data handling for electrophysiology recordings.</p> <p>See Ephys Data for detailed documentation.</p>"},{"location":"reference/utilities/#quality-assurance","title":"Quality Assurance","text":""},{"location":"reference/utilities/#qa_utils-module","title":"qa_utils Module","text":"<p>Tools for dataset quality assessment and validation.</p> <p>See QA Tools for detailed documentation.</p>"},{"location":"reference/utilities/#helper-scripts","title":"Helper Scripts","text":""},{"location":"reference/utilities/#infer_rnn_ratespy","title":"infer_rnn_rates.py","text":"<p>Infer firing rates from spike trains using RNN.</p> <pre><code>python utils/infer_rnn_rates.py &lt;data_dir&gt; [options]\n</code></pre> <p>Options:</p> <ul> <li><code>--train_steps</code>: Number of training steps</li> <li><code>--hidden_size</code>: RNN hidden layer size</li> <li><code>--bin_size</code>: Spike binning size</li> <li><code>--retrain</code>: Force model retraining</li> </ul>"},{"location":"reference/utilities/#blech_data_summarypy","title":"blech_data_summary.py","text":"<p>Generate comprehensive dataset summary.</p> <pre><code>python utils/blech_data_summary.py\n</code></pre>"},{"location":"reference/utilities/#grade_datasetpy","title":"grade_dataset.py","text":"<p>Grade dataset quality based on metrics.</p> <pre><code>python utils/grade_dataset.py\n</code></pre>"},{"location":"reference/utilities/#configuration-management","title":"Configuration Management","text":""},{"location":"reference/utilities/#parameter-files","title":"Parameter Files","text":"<p>Utilities for loading and managing parameter files:</p> <ul> <li>JSON parameter loading</li> <li>Parameter validation</li> <li>Default value handling</li> </ul>"},{"location":"reference/utilities/#example","title":"Example","text":"<pre><code>import json\n\n# Load parameters\nwith open('params/sorting_params.json', 'r') as f:\n    params = json.load(f)\n\n# Access parameters\nmax_clusters = params['max_clusters']\nmin_cluster_size = params['min_cluster_size']\n</code></pre>"},{"location":"reference/utilities/#file-io","title":"File I/O","text":""},{"location":"reference/utilities/#hdf5-operations","title":"HDF5 Operations","text":"<p>Functions for reading and writing HDF5 files:</p> <pre><code>import tables\n\n# Open HDF5 file\nwith tables.open_file('data.h5', 'r') as hf5:\n    # Read spike times\n    spike_times = hf5.root.spike_times[:]\n\n    # Read unit information\n    units = hf5.root.units[:]\n</code></pre>"},{"location":"reference/utilities/#binary-data","title":"Binary Data","text":"<p>Functions for reading Intan binary data:</p> <ul> <li>Amplifier data (<code>.dat</code> files)</li> <li>Digital input data (DIN files)</li> <li>Auxiliary input data</li> </ul>"},{"location":"reference/utilities/#see-also","title":"See Also","text":"<ul> <li>Core Pipeline</li> <li>Ephys Data</li> <li>QA Tools</li> </ul>"}]}